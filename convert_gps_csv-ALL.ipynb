{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import gpxpy \n",
    "import gpxpy.gpx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pendulum\n",
    "import pydarksky\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "from glob import glob\n",
    "from xml.dom import minidom\n",
    "#from gpx_csv_converter import Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify gpx_csv_converter CLASS\n",
    "\n",
    "# #https://ocefpaf.github.io/python4oceanographers/blog/2014/08/18/gpx/\n",
    "\n",
    "def iso_to_epoch(iso_time):\n",
    "    return calendar.timegm(dateutil.parser.parse(iso_time).timetuple())\n",
    "\n",
    "\n",
    "class Converter:\n",
    "\n",
    "    def __init__(self, string, name):\n",
    "\n",
    "        if name[-4:] != '.csv':\n",
    "            name = name + '.csv'\n",
    "\n",
    "        # parse an xml file by name\n",
    "        mydoc = minidom.parseString(string)\n",
    "\n",
    "        trkpt = mydoc.getElementsByTagName('trkpt')\n",
    "        time = mydoc.getElementsByTagName('time')\n",
    "        ele = mydoc.getElementsByTagName('ele')\n",
    "        hr = mydoc.getElementsByTagName('gpxtpx:hr')\n",
    "        cad = mydoc.getElementsByTagName('gpxtpx:cad')\n",
    "        temp = mydoc.getElementsByTagName('gpxtpx:atemp')\n",
    "        \n",
    "        #hr = mydoc.getElementsByTagName('ns3:hr')\n",
    "        #cad = mydoc.getElementsByTagName('ns3:cad')\n",
    "\n",
    "        lats = []\n",
    "        longs = []\n",
    "        times = []\n",
    "        eles = []\n",
    "        hrs = []\n",
    "        dates = []\n",
    "        parsed_times = []\n",
    "        cads = []\n",
    "        temps = []\n",
    "\n",
    "        for elem in trkpt:\n",
    "            lats.append(elem.attributes['lat'].value)\n",
    "            longs.append(elem.attributes['lon'].value)\n",
    "\n",
    "        for elem in time:\n",
    "            times.append(elem.firstChild.data)\n",
    "\n",
    "        for elem in hr:\n",
    "            hrs.append(elem.firstChild.data)\n",
    "\n",
    "        base_time = iso_to_epoch(times[0])\n",
    "\n",
    "        time_differences = []\n",
    "\n",
    "        for item in times:\n",
    "            time_differences.append(iso_to_epoch(item) - base_time)\n",
    "            date_obj = (dateutil.parser.parse(item))\n",
    "            dates.append(str(date_obj.year) + \"-\" + str(date_obj.month) + \"-\" + str(date_obj.day))\n",
    "            parsed_times.append(str(date_obj.hour) + \":\" + str(date_obj.minute) + \":\" + str(date_obj.second))\n",
    "\n",
    "        for elem in ele:\n",
    "            eles.append(elem.firstChild.data)\n",
    "\n",
    "        for elem in cad:\n",
    "            cads.append(elem.firstChild.data)\n",
    "   \n",
    "        for elem in temp:\n",
    "            temps.append(elem.firstChild.data)\n",
    "        \n",
    "        \n",
    "        hrs.append(0)\n",
    "\n",
    "        data = {'date': pd.Series(dates),\n",
    "                'time': pd.Series(parsed_times),\n",
    "                'latitude': pd.Series(lats),\n",
    "                'longitude': pd.Series(longs),\n",
    "                'elevation': pd.Series(eles),\n",
    "                'heart_rate': pd.Series(hrs),\n",
    "                'cadence': pd.Series(cads),\n",
    "                'temperature': pd.Series(temps)}\n",
    "\n",
    "        #print(len(dates), len(parsed_times), len(lats), len(longs), len(eles), len(hrs), len(cads), len(temps))\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "\n",
    "        df = df[['date', 'time', 'latitude', 'longitude', 'elevation', 'heart_rate', 'cadence', 'temperature']]\n",
    "\n",
    "        df.to_csv(name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " path from gpx:\n",
      " ['gpx\\\\Snow_corridor_Street_porridge.gpx', 'gpx\\\\Snow_waist_Water_under_snow_Hard_snow.gpx', 'gpx\\\\Some_intervals_in_snow_Frosty_roads.gpx']\n",
      "\n",
      " path to csv: \n",
      " ['csv\\\\Snow_corridor_Street_porridge.csv', 'csv\\\\Snow_waist_Water_under_snow_Hard_snow.csv', 'csv\\\\Some_intervals_in_snow_Frosty_roads.csv']\n"
     ]
    }
   ],
   "source": [
    "# Path to data - files operations\n",
    "\n",
    "#PATH_TO_DATA = '~/geekhubds/project/'\n",
    "PATH_TO_DATA = os.path.abspath(os.curdir)\n",
    "path_to_files = 'gpx\\*'\n",
    "\n",
    "# File operations\n",
    "file_quant = len(glob(path_to_files))\n",
    "file_names = [file for file in glob(path_to_files)]\n",
    "file_length = len(file_names)\n",
    "\n",
    "#files_gpx = os.listdir('gpx')\n",
    "#files_gpx = [('gpx\\\\' + file) for file in os.listdir('gpx')]\n",
    "files_csv = [ ('csv\\\\' + file[:len(file) - 4] + '.csv') for file in os.listdir('gpx')]\n",
    "\n",
    "print(' path from gpx:\\n',file_names)\n",
    "print('\\n path to csv: \\n',files_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: 1 -> gpx\\Snow_corridor_Street_porridge.gpx  time: 4 s \n",
      "\n",
      "file: 2 -> gpx\\Snow_waist_Water_under_snow_Hard_snow.gpx  time: 5 s \n",
      "\n",
      "file: 3 -> gpx\\Some_intervals_in_snow_Frosty_roads.gpx  time: 4 s \n",
      "\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# OPEN file for XML parse\n",
    "\n",
    "gpx_file_xml = []\n",
    "\n",
    "# convert gpx -> csv\n",
    "for ind, (csv, file) in enumerate(zip(files_csv, file_names)):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    gpx_file = open( file, 'r' )\n",
    "    gpx_file_str = gpx_file.read()\n",
    "    \n",
    "    # parse gps by xml tags\n",
    "    Converter(gpx_file_str, csv[:len(csv) - 4])\n",
    "   \n",
    "    gpx_file.close()\n",
    "    \n",
    "    end_time = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(f'file: {ind + 1} -> {file}  time: {end_time:.0f} s \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: 1 -> gpx\\Snow_corridor_Street_porridge.gpx  time: 2 s \n",
      "\n",
      "file: 2 -> gpx\\Snow_waist_Water_under_snow_Hard_snow.gpx  time: 2 s \n",
      "\n",
      "file: 3 -> gpx\\Some_intervals_in_snow_Frosty_roads.gpx  time: 2 s \n",
      "\n",
      "Wall time: 5.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# OPEN file gpx by libraries\n",
    "\n",
    "gpx_file_xml = []\n",
    "\n",
    "for ind, (csv, file) in enumerate(zip(files_csv, file_names)):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    gpx_file = open( file, 'r' )\n",
    "\n",
    "    gpx_file_xml_tmp =  gpxpy.parse(gpx_file)\n",
    "    gpx_file_xml.append(gpx_file_xml_tmp)\n",
    "    \n",
    "    gpx_file.close()\n",
    "    \n",
    "    end_time = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(f'file: {ind + 1} -> {file}  time: {end_time:.0f} s \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>data_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cadence</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:10</td>\n",
       "      <td>2019-01-28 13:56:10</td>\n",
       "      <td>49.409331</td>\n",
       "      <td>32.097608</td>\n",
       "      <td>90.4</td>\n",
       "      <td>97</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:10</td>\n",
       "      <td>2019-01-28 13:56:10</td>\n",
       "      <td>49.409345</td>\n",
       "      <td>32.097593</td>\n",
       "      <td>90.4</td>\n",
       "      <td>98</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:11</td>\n",
       "      <td>2019-01-28 13:56:11</td>\n",
       "      <td>49.409358</td>\n",
       "      <td>32.097570</td>\n",
       "      <td>90.2</td>\n",
       "      <td>98</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:12</td>\n",
       "      <td>2019-01-28 13:56:12</td>\n",
       "      <td>49.409369</td>\n",
       "      <td>32.097546</td>\n",
       "      <td>90.2</td>\n",
       "      <td>97</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:13</td>\n",
       "      <td>2019-01-28 13:56:13</td>\n",
       "      <td>49.409380</td>\n",
       "      <td>32.097521</td>\n",
       "      <td>90.2</td>\n",
       "      <td>97</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:14</td>\n",
       "      <td>2019-01-28 13:56:14</td>\n",
       "      <td>49.409392</td>\n",
       "      <td>32.097495</td>\n",
       "      <td>89.8</td>\n",
       "      <td>97</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:15</td>\n",
       "      <td>2019-01-28 13:56:15</td>\n",
       "      <td>49.409405</td>\n",
       "      <td>32.097469</td>\n",
       "      <td>89.8</td>\n",
       "      <td>97</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:16</td>\n",
       "      <td>2019-01-28 13:56:16</td>\n",
       "      <td>49.409411</td>\n",
       "      <td>32.097439</td>\n",
       "      <td>89.3</td>\n",
       "      <td>98</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:17</td>\n",
       "      <td>2019-01-28 13:56:17</td>\n",
       "      <td>49.409413</td>\n",
       "      <td>32.097411</td>\n",
       "      <td>89.1</td>\n",
       "      <td>98</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-1-28</td>\n",
       "      <td>13:56:18</td>\n",
       "      <td>2019-01-28 13:56:18</td>\n",
       "      <td>49.409405</td>\n",
       "      <td>32.097384</td>\n",
       "      <td>89.3</td>\n",
       "      <td>98</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      time           data_time   latitude  longitude  elevation  \\\n",
       "0  2019-1-28  13:56:10 2019-01-28 13:56:10  49.409331  32.097608       90.4   \n",
       "1  2019-1-28  13:56:10 2019-01-28 13:56:10  49.409345  32.097593       90.4   \n",
       "2  2019-1-28  13:56:11 2019-01-28 13:56:11  49.409358  32.097570       90.2   \n",
       "3  2019-1-28  13:56:12 2019-01-28 13:56:12  49.409369  32.097546       90.2   \n",
       "4  2019-1-28  13:56:13 2019-01-28 13:56:13  49.409380  32.097521       90.2   \n",
       "5  2019-1-28  13:56:14 2019-01-28 13:56:14  49.409392  32.097495       89.8   \n",
       "6  2019-1-28  13:56:15 2019-01-28 13:56:15  49.409405  32.097469       89.8   \n",
       "7  2019-1-28  13:56:16 2019-01-28 13:56:16  49.409411  32.097439       89.3   \n",
       "8  2019-1-28  13:56:17 2019-01-28 13:56:17  49.409413  32.097411       89.1   \n",
       "9  2019-1-28  13:56:18 2019-01-28 13:56:18  49.409405  32.097384       89.3   \n",
       "\n",
       "   heart_rate  cadence  temperature  \n",
       "0          97     61.0          NaN  \n",
       "1          98     61.0          NaN  \n",
       "2          98     61.0          NaN  \n",
       "3          97     61.0          NaN  \n",
       "4          97     61.0          NaN  \n",
       "5          97     85.0          NaN  \n",
       "6          97     85.0          NaN  \n",
       "7          98     85.0          NaN  \n",
       "8          98     84.0          NaN  \n",
       "9          98     83.0          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import converted csv files\n",
    "\n",
    "#user_data = [pd.read_csv(os.path.join('C:\\\\Users\\\\philka-ua\\\\geekhubds\\\\project\\\\',file)) for file in files_csv]\n",
    "user_data = [pd.read_csv(os.path.join(PATH_TO_DATA,file)) for file in files_csv]\n",
    "\n",
    "# Convert time and date to timestamp format (All files)\n",
    "[data.insert(2,'data_time',(data['date'] + ' ' + data['time'])\\\n",
    "        .apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ))) for data in user_data]\n",
    "\n",
    "# # Convert time and date to timestamp format (One file)\n",
    "# data_time_timestamp = (user_data[0]['date'] + ' ' + user_data[0]['time'])\\\n",
    "#         .apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ))\n",
    "# user_data[0].insert(2,'data_time',data_time_timestamp)\n",
    "\n",
    "# #user_data[0]['data_time'] = data_time_timestamp.values.astype('datetime64[s]').astype(datetime.datetime)\n",
    "# #user_data[0].insert(2,'data_time',data_time_timestamp.values.astype('datetime64[s]').astype(datetime.datetime))\n",
    "\n",
    "user_data[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GPX FAETURES adding (by the imported files with gpx libruary)\n",
    "\n",
    "\n",
    "# Segments of all gpx track\n",
    "all_segments = [*map(lambda x: x.tracks[0].segments[0], gpx_file_xml)]\n",
    "\n",
    "# Point for all gpx track\n",
    "all_points = [*map(lambda x: x.points, all_segments)]\n",
    "#[*map(lambda p: p.elevation, map(lambda x: x.points, all_segments) )]\n",
    "\n",
    "\n",
    "# ELEVATIONS\n",
    "\n",
    "# Elevation from gpx points\n",
    "def elevation_get(points):\n",
    "    '''get evaluation value from GPX point'''\n",
    "    return map(lambda e: e.elevation, points)\n",
    "\n",
    "# Elevation for all gpx tracks \n",
    "all_elevation = [*map(list, map(elevation_get, all_points))]\n",
    "#[[*map(lambda e: e.elevation, points)] for points in all_points]\n",
    "\n",
    "# Grade(Slopes) from gpx points\n",
    "def grade_get(points, steps=25):\n",
    "    '''get evaluation slope from GPX point'''\n",
    "    grd = []\n",
    "    \n",
    "    for ind, element in enumerate(points[:-steps]): \n",
    "        init_element = points[ind + steps]\n",
    "        delta_grd = element.elevation_angle(init_element)\n",
    "        \n",
    "        grd.append(delta_grd)\n",
    "    \n",
    "    grd = grd + [grd[-1]] * steps\n",
    "    \n",
    "    return  map(lambda x: round(x, 1), grd)\n",
    "   \n",
    "# function for elevation\n",
    "def uphill_gain(elevation):\n",
    "    '''get uphill in each point'''\n",
    "    up = [0]\n",
    "    init_element = elevation[0]\n",
    "\n",
    "    for element in elevation: \n",
    "        delta_elevation = element - init_element\n",
    "        init_element = element\n",
    "        if delta_elevation > 0:\n",
    "            up.append(up[-1] + delta_elevation)\n",
    "        else:\n",
    "            up.append(up[-1])\n",
    "    return list( map(lambda x: round(x, 5), up[1:]) )\n",
    "\n",
    "def downhill_loss(elevation):\n",
    "    '''get downhill in each point'''\n",
    "    dw = [0]\n",
    "    init_element = elevation[0]\n",
    "\n",
    "    for element in elevation: \n",
    "        delta_elevation = element - init_element\n",
    "        init_element = element\n",
    "        if delta_elevation < 0:\n",
    "            dw.append(dw[-1] + abs(delta_elevation))\n",
    "        else:\n",
    "            dw.append(dw[-1])\n",
    "    return list( map(lambda x: round(x, 1), dw[1:]) )\n",
    "\n",
    "def elevation_between(elevation):\n",
    "    '''get elevetions between each neighbours points from start'''\n",
    "    el = [0]\n",
    "    init_element = elevation[0]\n",
    "\n",
    "    for element in elevation: \n",
    "        delta_elevation = element - init_element\n",
    "        init_element = element\n",
    "        el.append(delta_elevation)\n",
    "\n",
    "    return list( map(lambda x: round(x, 5), el[1:]) )\n",
    "\n",
    "\n",
    "# grade (slope) for a few points\n",
    "all_grade = [*map(list, map(grade_get, all_points))]\n",
    "\n",
    "# uphill & downhill in each point\n",
    "all_uphill_gain = [*map(uphill_gain, all_elevation)]\n",
    "all_downhill_loss = [*map(downhill_loss, all_elevation)]\n",
    "\n",
    "# Elevation between each points\n",
    "all_elevation_between = [*map(elevation_between, all_elevation)]\n",
    "\n",
    "\n",
    "# SPEED\n",
    "\n",
    "# Speed in each point\n",
    "def speed_evaluating(segments):\n",
    "    '''evaluating speed in each point in km/hour'''\n",
    "    return map(lambda x: round(x * 3.6, 3), map(segments.get_speed, range(segments.points.__len__())) )\n",
    "\n",
    "all_speed = [*map(list, map(speed_evaluating, all_segments))]\n",
    "\n",
    "\n",
    "# DISTANCE\n",
    "\n",
    "# function for distance\n",
    "def dist_3d(points):\n",
    "    '''get distance_3d in each point from start'''\n",
    "    dst = [0]\n",
    "    init_element = points[0]\n",
    "\n",
    "    for element in points: \n",
    "        delta_dst = init_element.distance_3d(element)\n",
    "        dst.append(dst[-1] + delta_dst)\n",
    "    \n",
    "    return list( map(lambda x: round(x, 1), dst[1:]) )\n",
    "\n",
    "def dist_2d(points):\n",
    "    '''get distance_2d in each point from start'''\n",
    "    dst = [0]\n",
    "    init_element = points[0]\n",
    "\n",
    "    for element in points: \n",
    "        delta_dst = init_element.distance_2d(element)\n",
    "        dst.append(dst[-1] + delta_dst)\n",
    "    \n",
    "    return list( map(lambda x: round(x, 1), dst[1:]) )\n",
    "\n",
    "def dist__2d_between(points):\n",
    "    '''get distance_2d between each neighbours points from start'''\n",
    "    \n",
    "    dst = [0]\n",
    "    init_element = points[0]\n",
    "\n",
    "    for element in points: \n",
    "        delta_dst = init_element.distance_2d(element)\n",
    "        init_element = element\n",
    "        dst.append(delta_dst)\n",
    "    \n",
    "    return list( map(lambda x: round(x, 2), dst[1:]) )\n",
    "\n",
    "# distance evaluating for each point\n",
    "all_distance_2d = [*map(list, map(dist_2d, all_points))]\n",
    "all_distance_3d = [*map(list, map(dist_3d, all_points))]\n",
    "\n",
    "# distance evaluating for each point\n",
    "all_distance_between_2d = [*map(list, map(dist__2d_between, all_points))]\n",
    "\n",
    "\n",
    "# Gradient (my function)\n",
    "\n",
    "def gradient_get(data):\n",
    "    '''evaluating gradient in each point\n",
    "    \n",
    "    The steepness of ups and downs is called a slope. \n",
    "    The slope is expressed as a percentage and is determined by the formula:\n",
    "    grad = (elevation/distance) * 100\n",
    "    where elevation is the height of ascent or descent;\n",
    "    distance is the length of the ascent or descent.  \n",
    "    '''\n",
    "    if data[1] == 0:\n",
    "        grad = 0\n",
    "    else:\n",
    "        grad = (data[0]/data[1]) * 100\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def gradient_averge_get(data_points, step=50):\n",
    "    '''\n",
    "    evaluating avarge gradient for several points\n",
    "    \n",
    "    The steepness of ups and downs is called a slope. \n",
    "    The slope is expressed as a percentage and is determined by the formula:\n",
    "    grad = (elevation/distance) * 100\n",
    "    where elevation is the height of ascent or descent;\n",
    "    distance is the length of the ascent or descent.\n",
    "    '''\n",
    "    elevation = []\n",
    "    distance = []\n",
    "    \n",
    "    for el, dst in data_points:\n",
    "        elevation.append(el)\n",
    "        distance.append(dst)\n",
    "         \n",
    "    grad_avarge = []\n",
    "    \n",
    "    for i in range(len(elevation) - step):\n",
    "    \n",
    "        if sum(distance[i:i+step]) != 0:\n",
    "               grad_avarge.append( sum(elevation[i:i+step]) / sum(distance[i:i+step]) * 100 )\n",
    "        else:\n",
    "               grad_avarge.append(0)\n",
    "        \n",
    "    return list( map(lambda x: round(x, 1), grad_avarge + [grad_avarge[-1]] * step) )\n",
    "\n",
    "# Elevations and distance in tuple\n",
    "elevation_distance = [*map(list, map(lambda x: zip(x[0],x[1]) , zip(all_elevation_between, all_distance_between_2d) ))]\n",
    "#elevation_distance = [*map(list, [zip(elv,dst) for elv,dst in zip(all_elevation_between, all_distance_between_2d)] )]\n",
    "\n",
    "# Slope in each point\n",
    "all_slope_points = [[*map(lambda x: round(x, 1), map(gradient_get, el_dist))] for el_dist in elevation_distance]\n",
    "# Slope by steps points\n",
    "all_slope_stp_points = [*map(gradient_averge_get,elevation_distance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add GPS fetures to csv files\n",
    "\n",
    "# # Fetures decribes\n",
    "#\n",
    "# speed - speed in each GPX pont\n",
    "# distance_2d - accumulating distance by GPX point (by lot and lat - parameters)\n",
    "# distance_3d - accumulating distance by GPX point (by elevation, lot and lat - parameters)\n",
    "# distance_points_2d - distance between each GPX points ( by lot and lat - parameters))\n",
    "# uphill_gain - accumulating elevation by GPX points - disribes uphill duaring moving track\n",
    "# downhill_loss - accumulating lost elevation by GPX points - disribes downhill duaring moving track\n",
    "# grade / slope - the steepness of ups and downs is called a slope. The slope is expressed as a percentage\n",
    "#               parameter evaluated for several (steps - parametr) GPX point - window method\n",
    "#               slope - evaluated by my function, grade - evaluated by bildin function in GPX library\n",
    "# slope_points - same parametr as grade / slope, but evaluated for each neighboring points\n",
    "\n",
    "\n",
    "column = ['speed', 'distance_2d', 'distance_3d', 'distance_points_2d', 'uphill_gain',\\\n",
    "          'downhill_loss','grade','slope','slope_points']\n",
    "\n",
    "user_data_features = []\n",
    "\n",
    "for sp, d2, d3, d2_bt, up, dw, gr, sl, slp, data in zip(all_speed, all_distance_2d, all_distance_3d,\\\n",
    "    all_distance_between_2d,all_uphill_gain,all_downhill_loss,all_grade,all_slope_stp_points, all_slope_points, user_data):\n",
    "    # stack parameters\n",
    "    stacked_array = np.vstack((sp, d2, d3, d2_bt, up, dw, gr, sl, slp)).T\n",
    "    \n",
    "    df = pd.DataFrame(stacked_array,columns=column)\n",
    "    \n",
    "    # result dataframe\n",
    "    user_data_features.append( pd.concat([data, df], axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>data_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cadence</th>\n",
       "      <th>temperature</th>\n",
       "      <th>speed</th>\n",
       "      <th>distance_2d</th>\n",
       "      <th>distance_3d</th>\n",
       "      <th>distance_points_2d</th>\n",
       "      <th>uphill_gain</th>\n",
       "      <th>downhill_loss</th>\n",
       "      <th>grade</th>\n",
       "      <th>slope</th>\n",
       "      <th>slope_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-1-25</td>\n",
       "      <td>13:4:52</td>\n",
       "      <td>2019-01-25 13:04:52</td>\n",
       "      <td>49.409354</td>\n",
       "      <td>32.097220</td>\n",
       "      <td>88.6</td>\n",
       "      <td>91</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-1-25</td>\n",
       "      <td>13:4:52</td>\n",
       "      <td>2019-01-25 13:04:52</td>\n",
       "      <td>49.409346</td>\n",
       "      <td>32.097205</td>\n",
       "      <td>88.7</td>\n",
       "      <td>91</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.812</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-1-25</td>\n",
       "      <td>13:4:53</td>\n",
       "      <td>2019-01-25 13:04:53</td>\n",
       "      <td>49.409333</td>\n",
       "      <td>32.097190</td>\n",
       "      <td>88.5</td>\n",
       "      <td>91</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.119</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-1-25</td>\n",
       "      <td>13:4:54</td>\n",
       "      <td>2019-01-25 13:04:54</td>\n",
       "      <td>49.409300</td>\n",
       "      <td>32.097145</td>\n",
       "      <td>88.6</td>\n",
       "      <td>91</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.683</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-1-25</td>\n",
       "      <td>13:4:55</td>\n",
       "      <td>2019-01-25 13:04:55</td>\n",
       "      <td>49.409300</td>\n",
       "      <td>32.097145</td>\n",
       "      <td>88.6</td>\n",
       "      <td>91</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.135</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     time           data_time   latitude  longitude  elevation  \\\n",
       "0  2019-1-25  13:4:52 2019-01-25 13:04:52  49.409354  32.097220       88.6   \n",
       "1  2019-1-25  13:4:52 2019-01-25 13:04:52  49.409346  32.097205       88.7   \n",
       "2  2019-1-25  13:4:53 2019-01-25 13:04:53  49.409333  32.097190       88.5   \n",
       "3  2019-1-25  13:4:54 2019-01-25 13:04:54  49.409300  32.097145       88.6   \n",
       "4  2019-1-25  13:4:55 2019-01-25 13:04:55  49.409300  32.097145       88.6   \n",
       "\n",
       "   heart_rate  cadence  temperature   speed  distance_2d  distance_3d  \\\n",
       "0          91     63.0          NaN   5.070          0.0          0.0   \n",
       "1          91     62.0          NaN   5.812          1.4          1.4   \n",
       "2          91     62.0          NaN  12.119          4.6          4.6   \n",
       "3          91     62.0          NaN  17.683         12.7         12.7   \n",
       "4          91     62.0          NaN   8.135         20.8         20.8   \n",
       "\n",
       "   distance_points_2d  uphill_gain  downhill_loss  grade  slope  slope_points  \n",
       "0                0.00          0.0            0.0   -0.3   -1.4           0.0  \n",
       "1                1.40          0.1            0.0   -0.4   -1.4           7.1  \n",
       "2                1.81          0.1            0.2   -0.2   -1.5         -11.0  \n",
       "3                4.91          0.2            0.2   -0.3   -1.3           2.0  \n",
       "4                0.00          0.2            0.2   -0.3   -1.4           0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_features[2].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEATHER\n",
    "#\n",
    "# https://darksky.net/dev/docs\n",
    "# '''\n",
    "# UNITS\n",
    "# summary: Any summaries containing temperature or snow accumulation units will have their \n",
    "#          values in degrees Celsius or in centimeters (respectively).\n",
    "# nearestStormDistance: Kilometers.\n",
    "# precipIntensity: Millimeters per hour.\n",
    "# precipIntensityMax: Millimeters per hour.\n",
    "# precipAccumulation: Centimeters.\n",
    "# temperature: Degrees Celsius.\n",
    "# temperatureMin: Degrees Celsius.\n",
    "# temperatureMax: Degrees Celsius.\n",
    "# apparentTemperature: Degrees Celsius.\n",
    "# dewPoint: Degrees Celsius.\n",
    "# windSpeed: Meters per second.\n",
    "# windGust: Meters per second.\n",
    "# pressure: Hectopascals.\n",
    "# visibility: Kilometers.\n",
    "# '''\n",
    "\n",
    "# \"\"\"\n",
    "# Weather data parametrs\n",
    "\n",
    "# apparentTemperature: the apparent (or “feels like”) temperature in degrees Fahrenheit.\n",
    "# cloudCover: the percentage of sky occluded by clouds, between 0 and 1, inclusive.\n",
    "# dewPoint optional: the dew point in degrees Fahrenheit.\n",
    "# humidity optional: The relative humidity, between 0 and 1, inclusive.\n",
    "# icon optional: A machine-readable text summary of this data point, suitable for selecting an icon for display. \n",
    "#               one of the following values: clear-day, clear-night, rain, snow, sleet, wind, fog, cloudy,\n",
    "#               partly-cloudy-day, or partly-cloudy-night.\n",
    "# ozone: the columnar density of total atmospheric ozone at the given time in Dobson units.\n",
    "# precipAccumulation optional: The amount of snowfall accumulation expected to occur, in inches. \n",
    "#                              (If no snowfall is expected, this property will not be defined.)\n",
    "# precipIntensity optional: The intensity (in inches of liq. water per hour) of precipitation occurring at the given time.\n",
    "#                           This value is conditional on probability (that is, assuming any precipitation occurs at all).\n",
    "# precipProbability optional: The probability of precipitation occurring, between 0 and 1, inclusive.\n",
    "# precipType optional: The type of precipitation occurring at the given time. \n",
    "#                    If defined, this property will have one of the following values: \"rain\", \"snow\", or \"sleet\"tery mix”).\n",
    "# pressure optional: The sea-level air pressure in millibars.\n",
    "# summary optional: A human-readable text summary of this data point.\n",
    "# temperature optional: The air temperature in degrees Fahrenheit.\n",
    "# uvIndex optional: The UV index.\n",
    "# visibility optional: The average visibility in miles, capped at 10 miles.\n",
    "# windBearing optional: The direction that the wind is coming from in degrees, with true north at 0°  \n",
    "#                       and progressing clockwise. (If windSpeed is zero, then this value will not be defined.)\n",
    "# windGust optional: The wind gust speed in miles per hour.\n",
    "# windSpeed optional: The wind speed in miles per hour.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Weather data\n",
    "\n",
    "def weather_metric(data):\n",
    "    '''weather get api Darsky'''\n",
    "    \n",
    "    # Pre-define values for weather history\n",
    "    #7dc0ac0a1c0e06acfb268f9e66eea991\n",
    "    #f1a0a87113118f0b07a88f126e7d70e3\n",
    "    \n",
    "    darksky = pydarksky.DarkSky('f1a0a87113118f0b07a88f126e7d70e3')\n",
    "    darksky.lang = 'English'\n",
    "    darksky.units = \"si\"\n",
    "    darksky.exclude = ['minutely', 'alerts', 'flags']\n",
    "    \n",
    "    # weater request\n",
    "    weather = darksky.weather(longitude=data[0][2], latitude=data[0][1], date=data[0][0])\n",
    "    return weather\n",
    "\n",
    "def hourly_data_choose(data):\n",
    "    '''evaluate index'''\n",
    "    start_gps_time = int((data[0].to_pydatetime() - datetime.datetime(1970,1,1)).total_seconds())\n",
    "         \n",
    "    index_hour_24 = min( map(lambda x: (x[0], abs(x[1] - start_gps_time)), enumerate(hour_24)), key = lambda t: t[1] )[0]\n",
    "    \n",
    "    return index_hour_24\n",
    "\n",
    "\n",
    "def weather_main(user_data):\n",
    "    '''add weather data to csv file -> result pd.DataFrame'''\n",
    "    global hour_24\n",
    "    \n",
    "    # Main gps points data for API request\n",
    "    datas = user_data[['data_time','latitude','longitude']].values\n",
    "\n",
    "    # 24 hours segments\n",
    "    hourly_data = weather_metric(datas).json['hourly']['data']\n",
    "    hour_24 = [hour['time'] for hour in hourly_data]\n",
    "    \n",
    "    # Columns for DataFrame\n",
    "    columns_data = list( hourly_data[0].keys() )\n",
    "\n",
    "    # index evaluating\n",
    "    index_hour_24 = map(hourly_data_choose, datas)\n",
    "\n",
    "    # weather evaluating by index\n",
    "    weather_hourly_data = list( map(lambda x: [*x.values()], map(lambda x: hourly_data[x], index_hour_24) ) )\n",
    "    \n",
    "    # dataframes from weather data\n",
    "    column = ['time','summary','icon','precipIntensity','precipProbability','Temperature','apparentTemperature',\\\n",
    "        'dewPoint','humidity','pressure','windSpeed','windGust','windBearing','cloudCover','uvIndex','visibility','ozone']\n",
    "    df_weather = pd.DataFrame(np.vstack((weather_hourly_data)),columns=columns_data)\n",
    "\n",
    "    # result dataframe\n",
    "    result_user_data = pd.concat([user_data.loc[:,'data_time':],\\\n",
    "                                  df_weather.loc[:, 'summary':'ozone']], axis=1)\n",
    "    \n",
    "    return result_user_data\n",
    "\n",
    "#user_data_weather = list( map(weather_main, user_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: 1 -> gpx\\Snow_corridor_Street_porridge.gpx  time: 1 s \n",
      "\n",
      "file: 2 -> gpx\\Snow_waist_Water_under_snow_Hard_snow.gpx  time: 1 s \n",
      "\n",
      "file: 3 -> gpx\\Some_intervals_in_snow_Frosty_roads.gpx  time: 1 s \n",
      "\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add weather data to csv files\n",
    "\n",
    "user_data_weather = []\n",
    "\n",
    "for ind, (data, file) in enumerate(zip(user_data_features, file_names)):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    user_data_weather.append(weather_main(data))\n",
    "    \n",
    "    end_time = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(f'file: {ind + 1} -> {file}  time: {end_time:.0f} s \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cadence</th>\n",
       "      <th>temperature</th>\n",
       "      <th>speed</th>\n",
       "      <th>distance_2d</th>\n",
       "      <th>distance_3d</th>\n",
       "      <th>...</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>windGust</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>ozone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-27 13:10:00</td>\n",
       "      <td>49.409740</td>\n",
       "      <td>32.099832</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.22</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>403.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-27 13:10:00</td>\n",
       "      <td>49.409756</td>\n",
       "      <td>32.099837</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.270</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.22</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>403.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-27 13:10:01</td>\n",
       "      <td>49.409773</td>\n",
       "      <td>32.099853</td>\n",
       "      <td>85.9</td>\n",
       "      <td>85</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.985</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.22</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>403.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27 13:10:02</td>\n",
       "      <td>49.409770</td>\n",
       "      <td>32.099859</td>\n",
       "      <td>85.9</td>\n",
       "      <td>86</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.445</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.22</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>403.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-27 13:10:03</td>\n",
       "      <td>49.409789</td>\n",
       "      <td>32.099889</td>\n",
       "      <td>85.9</td>\n",
       "      <td>86</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.286</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.61</td>\n",
       "      <td>8.22</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>403.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            data_time   latitude  longitude  elevation  heart_rate  cadence  \\\n",
       "0 2019-01-27 13:10:00  49.409740  32.099832       85.8          85      0.0   \n",
       "1 2019-01-27 13:10:00  49.409756  32.099837       85.8          85      0.0   \n",
       "2 2019-01-27 13:10:01  49.409773  32.099853       85.9          85     81.0   \n",
       "3 2019-01-27 13:10:02  49.409770  32.099859       85.9          86     81.0   \n",
       "4 2019-01-27 13:10:03  49.409789  32.099889       85.9          86     81.0   \n",
       "\n",
       "   temperature  speed  distance_2d  distance_3d   ...    dewPoint  humidity  \\\n",
       "0          NaN  6.543          0.0          0.0   ...        -8.4      0.84   \n",
       "1          NaN  7.270          1.8          1.8   ...        -8.4      0.84   \n",
       "2          NaN  4.985          5.8          5.8   ...        -8.4      0.84   \n",
       "3          NaN  6.445          9.7          9.7   ...        -8.4      0.84   \n",
       "4          NaN  9.286         16.5         16.5   ...        -8.4      0.84   \n",
       "\n",
       "   pressure  windSpeed  windGust  windBearing cloudCover uvIndex visibility  \\\n",
       "0      1005       5.61      8.22          314          1       0      16.09   \n",
       "1      1005       5.61      8.22          314          1       0      16.09   \n",
       "2      1005       5.61      8.22          314          1       0      16.09   \n",
       "3      1005       5.61      8.22          314          1       0      16.09   \n",
       "4      1005       5.61      8.22          314          1       0      16.09   \n",
       "\n",
       "    ozone  \n",
       "0  403.83  \n",
       "1  403.83  \n",
       "2  403.83  \n",
       "3  403.83  \n",
       "4  403.83  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_weather[1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_time              2019-01-27 13:10:00\n",
       "latitude                           49.4097\n",
       "longitude                          32.0998\n",
       "elevation                             85.8\n",
       "heart_rate                              85\n",
       "cadence                                  0\n",
       "temperature                            NaN\n",
       "speed                                6.543\n",
       "distance_2d                              0\n",
       "distance_3d                              0\n",
       "distance_points_2d                       0\n",
       "uphill_gain                              0\n",
       "downhill_loss                            0\n",
       "grade                                  0.9\n",
       "slope                                  1.3\n",
       "slope_points                             0\n",
       "summary                           Overcast\n",
       "icon                                cloudy\n",
       "precipIntensity                      0.033\n",
       "precipProbability                     0.08\n",
       "precipAccumulation                   0.048\n",
       "precipType                            snow\n",
       "temperature                          -6.08\n",
       "apparentTemperature                 -12.93\n",
       "dewPoint                              -8.4\n",
       "humidity                              0.84\n",
       "pressure                              1005\n",
       "windSpeed                             5.61\n",
       "windGust                              8.22\n",
       "windBearing                            314\n",
       "cloudCover                               1\n",
       "uvIndex                                  0\n",
       "visibility                           16.09\n",
       "ozone                               403.83\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_weather[1].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " path to csv: \n",
      "\n",
      " ['csv_weather_fetures\\\\Snow_corridor_Street_porridge.csv', 'csv_weather_fetures\\\\Snow_waist_Water_under_snow_Hard_snow.csv', 'csv_weather_fetures\\\\Some_intervals_in_snow_Frosty_roads.csv']\n",
      "\n",
      " file: 1 -> csv_weather_fetures\\Snow_corridor_Street_porridge.csv  time: 0 s \n",
      "\n",
      " file: 2 -> csv_weather_fetures\\Snow_waist_Water_under_snow_Hard_snow.csv  time: 0 s \n",
      "\n",
      " file: 3 -> csv_weather_fetures\\Some_intervals_in_snow_Frosty_roads.csv  time: 0 s \n"
     ]
    }
   ],
   "source": [
    "# EXPORT to csv\n",
    "\n",
    "# Path to data - files operations\n",
    "files_csv_features = [ ('csv_weather_fetures\\\\' + file[:len(file) - 4] + '.csv') for file in os.listdir('csv')]\n",
    "print('\\n path to csv: \\n\\n',files_csv_features)\n",
    "\n",
    "# export to csv files\n",
    "\n",
    "for ind, (data, file) in enumerate(zip(user_data_weather, files_csv_features)):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    data.to_csv(path_or_buf=file)\n",
    "    \n",
    "    end_time = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(f'\\n file: {ind + 1} -> {file}  time: {end_time:.0f} s ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "\n",
    "# current_dir = get_ipython().getoutput('pwd')\n",
    "# module_path = Path(current_dir[0]).parent\n",
    "\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(str(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPX PARSE VARIANTS\n",
    "\n",
    "# # File OPEN variants\n",
    "\n",
    "# # 1 variant\n",
    "# gpx_file = open('Some_intervals_in_snow_Frosty_roads.gpx', 'r')\n",
    "# gpx_file.close()\n",
    "# gpx_file\n",
    "\n",
    "# # 2 variant\n",
    "# with open('gpx\\Cold_winds_Chygyryn_region.gpx','r') as gpxfile:\n",
    "#     gpx = gpxpy.parse(gpxfile)\n",
    "# gpx.tracks[0].segments[0].points;\n",
    "\n",
    "# # 3 variant\n",
    "# gpx_file = open( 'gpx\\Cold_winds_Chygyryn_region.gpx', 'r' )\n",
    "# gpx_parser = parser.GPXParser( gpx_file )\n",
    "# gpx_parser.parse()\n",
    "# #gpx_file.close()\n",
    "# gpx_parser.gpx.tracks[0].segments[0].points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpxpy.parser as parser\n",
    "\n",
    "# gpx_file = open( 'Some_intervals_in_snow_Frosty_roads.gpx', 'r' )\n",
    "\n",
    "# gpx_parser = parser.GPXParser( gpx_file )\n",
    "# gpx_parser.parse()\n",
    "\n",
    "# gpx_file.close()\n",
    "\n",
    "# gpx = gpx_parser.get_gpx()\n",
    "\n",
    "# for track in gpx.tracks:\n",
    "#     for segment in track.segments:\n",
    "#         for point in segment.points:\n",
    "#             print('Point at ({0},{1}) -> {2}'.format( point.latitude, point.longitude, point.elevation ))\n",
    "\n",
    "# for waypoint in gpx.waypoints:\n",
    "#     print( 'waypoint {0} -> ({1},{2})'.format( waypoint.name, waypoint.latitude, waypoint.longitude ))\n",
    "\n",
    "# for route in gpx.routes:\n",
    "#     print('Route:')\n",
    "#     for point in route:\n",
    "#         print( 'Point at ({0},{1}) -> {2}'.format( point.latitude, point.longitude, point.elevation ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parsegpx():\n",
    "#     points2 = list()\n",
    "#     with open('Some_intervals_in_snow_Frosty_roads.gpx','r') as gpxfile:\n",
    "#         gpx = gpxpy.parse(gpxfile)\n",
    "#         for track in gpx.tracks:\n",
    "#             for segment in track.segments:\n",
    "#                 for point in segment.points:\n",
    "#                     dict = {'Timestamp': point.time,\n",
    "#                             'Latitude': point.latitude,\n",
    "#                             'Longitude': point.longitude,\n",
    "#                             'Elevation': point.elevation\n",
    "#                             }\n",
    "#                     points2.append(dict)\n",
    "#     print(points2)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     parsegpx();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weather History Data \n",
    "\n",
    "# # # Weather History Data API REQUEST\n",
    "\n",
    "# # # API parameters\n",
    "# # secret_key = '7dc0ac0a1c0e06acfb268f9e66eea991'\n",
    "# # lat, lon = str(user_data[0].loc[0].latitude), str(user_data[0].loc[0].longitude)\n",
    "# # start_time = int((user_data[0].loc[0].data_time - datetime.datetime(1970,1,1)).total_seconds())\n",
    "# # #user_data[0].loc[0].data_time.to_pydatetime()\n",
    "\n",
    "# # # Get request\n",
    "# # data = requests.get(f\"https://api.darksky.net/forecast/{secret_key}/{lat},{lon},{start_time}\\\n",
    "# # ?exclude=hourly,daily,minutely,alerts,flags?units=si\").json()\n",
    "# # data\n",
    "\n",
    "# # Pre-define values\n",
    "# #f1a0a87113118f0b07a88f126e7d70e3\n",
    "# #7dc0ac0a1c0e06acfb268f9e66eea991\n",
    "# darksky = pydarksky.DarkSky('f1a0a87113118f0b07a88f126e7d70e3')\n",
    "# darksky.lang = 'Ukrainian'\n",
    "# darksky.units = \"si\"\n",
    "# darksky.exclude = ['minutely', 'alerts', 'flags']\n",
    "\n",
    "# # weater request\n",
    "# weather = darksky.weather(longitude=user_data[0].loc[0].longitude, latitude=user_data[0].loc[0].latitude,\\\n",
    "#                           date=user_data[0].loc[0].data_time.to_pydatetime())\n",
    "# hourly_data = weather.json['hourly']['data']\n",
    "\n",
    "# # 24 hours segments\n",
    "# hour_24 = [hour['time'] for hour in weather.json['hourly']['data']]\n",
    "\n",
    "# # pasred time\n",
    "# # map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ))\n",
    "# # print(datetime.datetime.utcfromtimestamp(hour_24[0]).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# #actual_time = datetime.datetime.utcfromtimestamp(start_time)\n",
    "# #actual_time = int((user_data[0].loc[0].data_time.to_pydatetime() - datetime.datetime(1970,1,1)).total_seconds())\n",
    "# actual_time = user_data[0].loc[0].data_time.to_pydatetime()\n",
    "\n",
    "# # difference time evaluating\n",
    "# difference_time = list( map(lambda x: abs(datetime.datetime.utcfromtimestamp(x) - actual_time), hour_24) )\n",
    "\n",
    "# # index of actual time\n",
    "# index_hour_24 = difference_time.index(min(difference_time))\n",
    "# print(datetime.datetime.utcfromtimestamp(hour_24[index_hour_24]).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "\n",
    "# weather.json['hourly']['data'][index_hour_24]\n",
    "\n",
    "# [print(datetime.datetime.utcfromtimestamp(weather.hourly[i].time).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "#        ' -> ',weather.hourly[i].temperature) for i in range(24)];\n",
    "\n",
    "# print(f'\\n Daily weather metrics:\\n\\\n",
    "#     \\n ozone: {weather.daily[0].ozone}\\\n",
    "#     \\n moon Phase: {weather.daily[0].moonPhase}\\\n",
    "#     \\n icon: {weather.daily[0].icon}\\\n",
    "#     \\n humidity: {weather.daily[0].humidity}\\\n",
    "#     \\n dew Point: {weather.daily[0].dewPoint}\\\n",
    "#     \\n cloud Cover: {weather.daily[0].cloudCover}\\\n",
    "#     \\n apparent Temperature Low: {weather.daily[0].apparentTemperatureLow}\\\n",
    "#     \\n apparent Temperature High: {weather.daily[0].apparentTemperatureHigh}\\\n",
    "#     \\n pressure: {weather.daily[0].pressure}\\\n",
    "#     \\n uv Index: {weather.daily[0].uvIndex}\\\n",
    "#     \\n wind Speed: {weather.daily[0].windSpeed}\\\n",
    "#     \\n wind Gust: {weather.daily[0].windGust}\\\n",
    "#     \\n wind Bearing: {weather.daily[0].windBearing}\\\n",
    "#     \\n wind Gust: {weather.daily[0].windGust}\\\n",
    "#     \\n wind Gust: {weather.daily[0].windGust}\\\n",
    "#     \\n visibility: {weather.daily[0].visibility}\\\n",
    "#     \\n summary: {weather.daily[0].summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT CONVERT\n",
    "\n",
    "# import csv\n",
    "# import os\n",
    "# #to install fitparse, run \n",
    "# #sudo pip3 install -e git+https://github.com/dtcooper/python-fitparse#egg=python-fitparse\n",
    "# import fitparse\n",
    "# import pytz\n",
    "\n",
    "# allowed_fields = ['timestamp','position_lat','position_long', 'distance',\n",
    "# 'enhanced_altitude', 'altitude','enhanced_speed',\n",
    "#                  'speed', 'heart_rate','cadence','fractional_cadence']\n",
    "# required_fields = ['timestamp', 'position_lat', 'position_long', 'altitude']\n",
    "\n",
    "# UTC = pytz.UTC\n",
    "# CST = pytz.timezone('US/Central')\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     files = os.listdir()\n",
    "#     fit_files = [file for file in files if file[-4:].lower()=='.fit']\n",
    "#     for file in fit_files:\n",
    "#         new_filename = file[:-4] + '.csv'\n",
    "#         if os.path.exists(new_filename):\n",
    "#             #print('%s already exists. skipping.' % new_filename)\n",
    "#             continue\n",
    "#         fitfile = fitparse.FitFile(file,  \n",
    "#             data_processor=fitparse.StandardUnitsDataProcessor())\n",
    "        \n",
    "#         print('converting %s' % file)\n",
    "#         write_fitfile_to_csv(fitfile, new_filename)\n",
    "#     print('finished conversions')\n",
    "\n",
    "\n",
    "# def write_fitfile_to_csv(fitfile, output_file='test_output.csv'):\n",
    "#     messages = fitfile.messages\n",
    "#     data = []\n",
    "#     for m in messages:\n",
    "#         skip=False\n",
    "#         if not hasattr(m, 'fields'):\n",
    "#             continue\n",
    "#         fields = m.fields\n",
    "#         #check for important data types\n",
    "#         mdata = {}\n",
    "#         for field in fields:\n",
    "#             if field.name in allowed_fields:\n",
    "#                 if field.name=='timestamp':\n",
    "#                     mdata[field.name] = UTC.localize(field.value).astimezone(CST)\n",
    "#                 else:\n",
    "#                     mdata[field.name] = field.value\n",
    "#         for rf in required_fields:\n",
    "#             if rf not in mdata:\n",
    "#                 skip=True\n",
    "#         if not skip:\n",
    "#             data.append(mdata)\n",
    "#     #write to csv\n",
    "#     with open(output_file, 'w') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(allowed_fields)\n",
    "#         for entry in data:\n",
    "#             writer.writerow([ str(entry.get(k, '')) for k in allowed_fields])\n",
    "#     print('wrote %s' % output_file)\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
